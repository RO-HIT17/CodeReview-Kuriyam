{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jej9i6O3hUNb",
        "outputId": "fad691d7-12e9-4416-ad71-dcababc2497b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“˜ SecEval Ollama Benchmark Notebook (Colab)\n",
        "\n",
        "# ğŸ“¦ Install dependencies\n",
        "!pip install datasets requests"
      ],
      "id": "Jej9i6O3hUNb"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sfq0CbZ7hUNc"
      },
      "outputs": [],
      "source": [
        "# âš™ï¸ Setup\n",
        "import time\n",
        "import requests\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ğŸ”— Replace this with your ngrok/localtunnel/external link\n",
        "OLLAMA_API = \"https://be12-2405-201-e025-f0fb-7464-6fa0-ae1a-e93a.ngrok-free.app/\"  # e.g., https://abc123.loca.lt\n",
        "MODEL_NAME = \"qwen2.5-coder:latest\"  # or your custom model name in Ollama\n",
        "NUM_QUESTIONS = 30  # Set how many questions you want to evaluate"
      ],
      "id": "sfq0CbZ7hUNc"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P4RmKAM5hUNd"
      },
      "outputs": [],
      "source": [
        "def format_prompt(question, choices):\n",
        "    formatted_choices = \"\\n\".join([f\"{chr(65+i)}. {c}\" for i, c in enumerate(choices)])\n",
        "    return f\"\"\"You are given a multiple-choice question.\n",
        "\n",
        "Strictly Respond ONLY with capital letter of choice: A\n",
        "if multiple answers are correct respond lik : ABC (if A,B,C are correct then output shd be like this ABC no spaces or commas in middle)\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Choices:\n",
        "{formatted_choices}\n",
        "Answer:\"\"\"\n",
        "import re\n",
        "def extract_answer(output):\n",
        "    # Convert to uppercase to simplify matching\n",
        "    output = output.upper()\n",
        "\n",
        "    # Match multiple letters: A-D, with optional separators (space, comma, \"and\")\n",
        "    matches = re.findall(r'\\b[A-D]\\b', output)\n",
        "    if matches:\n",
        "        # Remove duplicates and sort\n",
        "        unique_answers = sorted(set(matches))\n",
        "        return ''.join(unique_answers)\n",
        "\n",
        "    # Fallback: match combined answers like \"AB\", \"ACD\"\n",
        "    match = re.search(r'\\b([A-D]{2,4})\\b', output)\n",
        "    if match:\n",
        "        return ''.join(sorted(set(match.group(1))))\n",
        "\n",
        "    return \"N/A\""
      ],
      "id": "P4RmKAM5hUNd"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNp-xp48hUNd",
        "outputId": "f4886a8d-c6ca-4657-8c12-27091e7dd919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Loading SecEval dataset from Hugging Face (via hf:// protocol)...\n",
            "âœ… Loaded 30 questions\n",
            "\n",
            "ğŸ“ Sample question:\n",
            "Q: You are tasked with designing a secure storage system for an Android device's hardware identifiers as part of an ID attestation implementation. Which of the following properties are essential for ensuring the system's integrity and security?\n",
            "Choices: ['A: The storage must contain the original identifiers to enable the TEE to verify their authenticity during attestation.', 'B: The storage should be tamper-evident to ensure any modification is detectable, rendering the attestation invalid.', 'C: The `destroyAttestationIds()` method should be able to restore the identifier-derived data after a factory reset.', 'D: RMA facilities must not have the ability to regenerate hardware identifier-derived data to prevent unauthorized attestation.']\n",
            "Answer: B\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“¥ Load dataset\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "# ğŸ”¢ Define number of questions\n",
        "NUM_QUESTIONS = 30  # Change if needed\n",
        "\n",
        "print(\"ğŸ“¥ Loading SecEval dataset from Hugging Face (via hf:// protocol)...\")\n",
        "\n",
        "\n",
        "df = pd.read_json(\"hf://datasets/XuanwuAI/SecEval/questions.json\")\n",
        "\n",
        "# ğŸ§¹ Trim to the first N questions\n",
        "df = df.iloc[:NUM_QUESTIONS].reset_index(drop=True)\n",
        "\n",
        "# ğŸ” Convert to Hugging Face dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "print(f\"âœ… Loaded {len(dataset)} questions\")\n",
        "\n",
        "# ğŸ“ Display a sample\n",
        "sample = dataset[0]\n",
        "print(f\"\\nğŸ“ Sample question:\")\n",
        "print(f\"Q: {sample['question']}\")\n",
        "print(f\"Choices: {sample['choices']}\")\n",
        "print(f\"Answer: {sample['answer']}\")"
      ],
      "id": "lNp-xp48hUNd"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kJ8EHM2hUNd",
        "outputId": "ca42011c-e777-48eb-f0af-f0bbcba61897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”„ Question 1/30\n",
            "ğŸ“¤ Model's Raw Output: ABCD\n",
            "ğŸ“ Prediction: ABCD\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 1.7 s\n",
            "\n",
            "ğŸ”„ Question 2/30\n",
            "ğŸ“¤ Model's Raw Output: B\n",
            "ğŸ“ Prediction: B\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.33 s\n",
            "\n",
            "ğŸ”„ Question 3/30\n",
            "ğŸ“¤ Model's Raw Output: B\n",
            "ğŸ“ Prediction: B\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.34 s\n",
            "\n",
            "ğŸ”„ Question 4/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.31 s\n",
            "\n",
            "ğŸ”„ Question 5/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.33 s\n",
            "\n",
            "ğŸ”„ Question 6/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.35 s\n",
            "\n",
            "ğŸ”„ Question 7/30\n",
            "ğŸ“¤ Model's Raw Output: ABC\n",
            "ğŸ“ Prediction: ABC\n",
            "âœ… Actual Answer: AB\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.4 s\n",
            "\n",
            "ğŸ”„ Question 8/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.37 s\n",
            "\n",
            "ğŸ”„ Question 9/30\n",
            "ğŸ“¤ Model's Raw Output: ABCD\n",
            "ğŸ“ Prediction: ABCD\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.38 s\n",
            "\n",
            "ğŸ”„ Question 10/30\n",
            "ğŸ“¤ Model's Raw Output: AD\n",
            "ğŸ“ Prediction: AD\n",
            "âœ… Actual Answer: AD\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.31 s\n",
            "\n",
            "ğŸ”„ Question 11/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.44 s\n",
            "\n",
            "ğŸ”„ Question 12/30\n",
            "ğŸ“¤ Model's Raw Output: D\n",
            "ğŸ“ Prediction: D\n",
            "âœ… Actual Answer: CD\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.35 s\n",
            "\n",
            "ğŸ”„ Question 13/30\n",
            "ğŸ“¤ Model's Raw Output: ABCD\n",
            "ğŸ“ Prediction: ABCD\n",
            "âœ… Actual Answer: BD\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.42 s\n",
            "\n",
            "ğŸ”„ Question 14/30\n",
            "ğŸ“¤ Model's Raw Output: A C\n",
            "ğŸ“ Prediction: AC\n",
            "âœ… Actual Answer: AC\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.42 s\n",
            "\n",
            "ğŸ”„ Question 15/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.33 s\n",
            "\n",
            "ğŸ”„ Question 16/30\n",
            "ğŸ“¤ Model's Raw Output: D\n",
            "ğŸ“ Prediction: D\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.35 s\n",
            "\n",
            "ğŸ”„ Question 17/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: ABC\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.39 s\n",
            "\n",
            "ğŸ”„ Question 18/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.38 s\n",
            "\n",
            "ğŸ”„ Question 19/30\n",
            "ğŸ“¤ Model's Raw Output: B\n",
            "ğŸ“ Prediction: B\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.32 s\n",
            "\n",
            "ğŸ”„ Question 20/30\n",
            "ğŸ“¤ Model's Raw Output: B\n",
            "ğŸ“ Prediction: B\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.34 s\n",
            "\n",
            "ğŸ”„ Question 21/30\n",
            "ğŸ“¤ Model's Raw Output: B\n",
            "ğŸ“ Prediction: B\n",
            "âœ… Actual Answer: AC\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.4 s\n",
            "\n",
            "ğŸ”„ Question 22/30\n",
            "ğŸ“¤ Model's Raw Output: A\n",
            "ğŸ“ Prediction: A\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.38 s\n",
            "\n",
            "ğŸ”„ Question 23/30\n",
            "ğŸ“¤ Model's Raw Output: D\n",
            "ğŸ“ Prediction: D\n",
            "âœ… Actual Answer: \n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.34 s\n",
            "\n",
            "ğŸ”„ Question 24/30\n",
            "ğŸ“¤ Model's Raw Output: ACD\n",
            "ğŸ“ Prediction: ACD\n",
            "âœ… Actual Answer: AB\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.37 s\n",
            "\n",
            "ğŸ”„ Question 25/30\n",
            "ğŸ“¤ Model's Raw Output: ACD\n",
            "ğŸ“ Prediction: ACD\n",
            "âœ… Actual Answer: ACD\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.39 s\n",
            "\n",
            "ğŸ”„ Question 26/30\n",
            "ğŸ“¤ Model's Raw Output: A D\n",
            "ğŸ“ Prediction: AD\n",
            "âœ… Actual Answer: AD\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.35 s\n",
            "\n",
            "ğŸ”„ Question 27/30\n",
            "ğŸ“¤ Model's Raw Output: B C D\n",
            "ğŸ“ Prediction: BCD\n",
            "âœ… Actual Answer: BCD\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.42 s\n",
            "\n",
            "ğŸ”„ Question 28/30\n",
            "ğŸ“¤ Model's Raw Output: B\n",
            "ğŸ“ Prediction: B\n",
            "âœ… Actual Answer: B\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.31 s\n",
            "\n",
            "ğŸ”„ Question 29/30\n",
            "ğŸ“¤ Model's Raw Output: B\n",
            "ğŸ“ Prediction: B\n",
            "âœ… Actual Answer: A\n",
            "ğŸ¯ Correct? âŒ No\n",
            "â±ï¸ Latency: 0.37 s\n",
            "\n",
            "ğŸ”„ Question 30/30\n",
            "ğŸ“¤ Model's Raw Output: AB\n",
            "ğŸ“ Prediction: AB\n",
            "âœ… Actual Answer: AB\n",
            "ğŸ¯ Correct? âœ… Yes\n",
            "â±ï¸ Latency: 0.32 s\n",
            "\n",
            "ğŸ¯ Results\n",
            "âœ… Accuracy: 63.33%\n",
            "â±ï¸ Avg Latency: 0.41s\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# ğŸš€ Benchmark\n",
        "correct = 0\n",
        "latencies = []\n",
        "\n",
        "for i, sample in enumerate(dataset):\n",
        "    print(f\"\\nğŸ”„ Question {i+1}/{NUM_QUESTIONS}\")\n",
        "\n",
        "    # Use sample directly (no json.loads needed)\n",
        "    prompt = format_prompt(sample[\"question\"], sample[\"choices\"])\n",
        "\n",
        "    # Send prompt to Ollama API\n",
        "    start = time.time()\n",
        "    response = requests.post(\n",
        "        f\"{OLLAMA_API}/api/generate\",\n",
        "        json={\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False\n",
        "        }\n",
        "    )\n",
        "    latency = time.time() - start\n",
        "\n",
        "    output_text = response.json().get(\"response\", \"\")\n",
        "    prediction = extract_answer(output_text)\n",
        "    actual = sample[\"answer\"].strip().upper()\n",
        "    is_correct = (prediction == actual)\n",
        "\n",
        "    correct += int(is_correct)\n",
        "    latencies.append(latency)\n",
        "\n",
        "    # ğŸ” Show model prediction and correct answer\n",
        "    print(\"ğŸ“¤ Model's Raw Output:\", output_text.strip())\n",
        "    print(\"ğŸ“ Prediction:\", prediction)\n",
        "    print(\"âœ… Actual Answer:\", actual)\n",
        "    print(\"ğŸ¯ Correct?\" , \"âœ… Yes\" if is_correct else \"âŒ No\")\n",
        "    print(\"â±ï¸ Latency:\", round(latency, 2), \"s\")\n",
        "\n",
        "accuracy = correct / NUM_QUESTIONS * 100\n",
        "avg_latency = sum(latencies) / NUM_QUESTIONS\n",
        "\n",
        "print(\"\\nğŸ¯ Results\")\n",
        "print(f\"âœ… Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"â±ï¸ Avg Latency: {avg_latency:.2f}s\")\n"
      ],
      "id": "5kJ8EHM2hUNd"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3mryYoMlMyj"
      },
      "id": "F3mryYoMlMyj",
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}