{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jej9i6O3hUNb",
        "outputId": "fad691d7-12e9-4416-ad71-dcababc2497b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# üìò SecEval Ollama Benchmark Notebook (Colab)\n",
        "\n",
        "# üì¶ Install dependencies\n",
        "!pip install datasets requests"
      ],
      "id": "Jej9i6O3hUNb"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sfq0CbZ7hUNc"
      },
      "outputs": [],
      "source": [
        "# ‚öôÔ∏è Setup\n",
        "import time\n",
        "import requests\n",
        "from datasets import load_dataset\n",
        "\n",
        "# üîó Replace this with your ngrok/localtunnel/external link\n",
        "OLLAMA_API = \"https://be12-2405-201-e025-f0fb-7464-6fa0-ae1a-e93a.ngrok-free.app/\"  # e.g., https://abc123.loca.lt\n",
        "MODEL_NAME = \"qwen2.5-coder:latest\"  # or your custom model name in Ollama\n",
        "NUM_QUESTIONS = 30  # Set how many questions you want to evaluate"
      ],
      "id": "sfq0CbZ7hUNc"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P4RmKAM5hUNd"
      },
      "outputs": [],
      "source": [
        "def format_prompt(question, choices):\n",
        "    formatted_choices = \"\\n\".join([f\"{chr(65+i)}. {c}\" for i, c in enumerate(choices)])\n",
        "    return f\"\"\"You are given a multiple-choice question.\n",
        "\n",
        "Strictly Respond ONLY with capital letter of choice: A\n",
        "if multiple answers are correct respond lik : ABC (if A,B,C are correct then output shd be like this ABC no spaces or commas in middle)\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Choices:\n",
        "{formatted_choices}\n",
        "Answer:\"\"\"\n",
        "import re\n",
        "def extract_answer(output):\n",
        "    # Convert to uppercase to simplify matching\n",
        "    output = output.upper()\n",
        "\n",
        "    # Match multiple letters: A-D, with optional separators (space, comma, \"and\")\n",
        "    matches = re.findall(r'\\b[A-D]\\b', output)\n",
        "    if matches:\n",
        "        # Remove duplicates and sort\n",
        "        unique_answers = sorted(set(matches))\n",
        "        return ''.join(unique_answers)\n",
        "\n",
        "    # Fallback: match combined answers like \"AB\", \"ACD\"\n",
        "    match = re.search(r'\\b([A-D]{2,4})\\b', output)\n",
        "    if match:\n",
        "        return ''.join(sorted(set(match.group(1))))\n",
        "\n",
        "    return \"N/A\""
      ],
      "id": "P4RmKAM5hUNd"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNp-xp48hUNd",
        "outputId": "f4886a8d-c6ca-4657-8c12-27091e7dd919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading SecEval dataset from Hugging Face (via hf:// protocol)...\n",
            "‚úÖ Loaded 30 questions\n",
            "\n",
            "üìù Sample question:\n",
            "Q: You are tasked with designing a secure storage system for an Android device's hardware identifiers as part of an ID attestation implementation. Which of the following properties are essential for ensuring the system's integrity and security?\n",
            "Choices: ['A: The storage must contain the original identifiers to enable the TEE to verify their authenticity during attestation.', 'B: The storage should be tamper-evident to ensure any modification is detectable, rendering the attestation invalid.', 'C: The `destroyAttestationIds()` method should be able to restore the identifier-derived data after a factory reset.', 'D: RMA facilities must not have the ability to regenerate hardware identifier-derived data to prevent unauthorized attestation.']\n",
            "Answer: B\n"
          ]
        }
      ],
      "source": [
        "# üì• Load dataset\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "# üî¢ Define number of questions\n",
        "NUM_QUESTIONS = 30  # Change if needed\n",
        "\n",
        "print(\"üì• Loading SecEval dataset from Hugging Face (via hf:// protocol)...\")\n",
        "\n",
        "\n",
        "df = pd.read_json(\"hf://datasets/XuanwuAI/SecEval/questions.json\")\n",
        "\n",
        "# üßπ Trim to the first N questions\n",
        "df = df.iloc[:NUM_QUESTIONS].reset_index(drop=True)\n",
        "\n",
        "# üîÅ Convert to Hugging Face dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(dataset)} questions\")\n",
        "\n",
        "# üìù Display a sample\n",
        "sample = dataset[0]\n",
        "print(f\"\\nüìù Sample question:\")\n",
        "print(f\"Q: {sample['question']}\")\n",
        "print(f\"Choices: {sample['choices']}\")\n",
        "print(f\"Answer: {sample['answer']}\")"
      ],
      "id": "lNp-xp48hUNd"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kJ8EHM2hUNd",
        "outputId": "ca42011c-e777-48eb-f0af-f0bbcba61897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Question 1/30\n",
            "üì§ Model's Raw Output: ABCD\n",
            "üìù Prediction: ABCD\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 1.7 s\n",
            "\n",
            "üîÑ Question 2/30\n",
            "üì§ Model's Raw Output: B\n",
            "üìù Prediction: B\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.33 s\n",
            "\n",
            "üîÑ Question 3/30\n",
            "üì§ Model's Raw Output: B\n",
            "üìù Prediction: B\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.34 s\n",
            "\n",
            "üîÑ Question 4/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.31 s\n",
            "\n",
            "üîÑ Question 5/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.33 s\n",
            "\n",
            "üîÑ Question 6/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.35 s\n",
            "\n",
            "üîÑ Question 7/30\n",
            "üì§ Model's Raw Output: ABC\n",
            "üìù Prediction: ABC\n",
            "‚úÖ Actual Answer: AB\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.4 s\n",
            "\n",
            "üîÑ Question 8/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.37 s\n",
            "\n",
            "üîÑ Question 9/30\n",
            "üì§ Model's Raw Output: ABCD\n",
            "üìù Prediction: ABCD\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.38 s\n",
            "\n",
            "üîÑ Question 10/30\n",
            "üì§ Model's Raw Output: AD\n",
            "üìù Prediction: AD\n",
            "‚úÖ Actual Answer: AD\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.31 s\n",
            "\n",
            "üîÑ Question 11/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.44 s\n",
            "\n",
            "üîÑ Question 12/30\n",
            "üì§ Model's Raw Output: D\n",
            "üìù Prediction: D\n",
            "‚úÖ Actual Answer: CD\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.35 s\n",
            "\n",
            "üîÑ Question 13/30\n",
            "üì§ Model's Raw Output: ABCD\n",
            "üìù Prediction: ABCD\n",
            "‚úÖ Actual Answer: BD\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.42 s\n",
            "\n",
            "üîÑ Question 14/30\n",
            "üì§ Model's Raw Output: A C\n",
            "üìù Prediction: AC\n",
            "‚úÖ Actual Answer: AC\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.42 s\n",
            "\n",
            "üîÑ Question 15/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.33 s\n",
            "\n",
            "üîÑ Question 16/30\n",
            "üì§ Model's Raw Output: D\n",
            "üìù Prediction: D\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.35 s\n",
            "\n",
            "üîÑ Question 17/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: ABC\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.39 s\n",
            "\n",
            "üîÑ Question 18/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.38 s\n",
            "\n",
            "üîÑ Question 19/30\n",
            "üì§ Model's Raw Output: B\n",
            "üìù Prediction: B\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.32 s\n",
            "\n",
            "üîÑ Question 20/30\n",
            "üì§ Model's Raw Output: B\n",
            "üìù Prediction: B\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.34 s\n",
            "\n",
            "üîÑ Question 21/30\n",
            "üì§ Model's Raw Output: B\n",
            "üìù Prediction: B\n",
            "‚úÖ Actual Answer: AC\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.4 s\n",
            "\n",
            "üîÑ Question 22/30\n",
            "üì§ Model's Raw Output: A\n",
            "üìù Prediction: A\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.38 s\n",
            "\n",
            "üîÑ Question 23/30\n",
            "üì§ Model's Raw Output: D\n",
            "üìù Prediction: D\n",
            "‚úÖ Actual Answer: \n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.34 s\n",
            "\n",
            "üîÑ Question 24/30\n",
            "üì§ Model's Raw Output: ACD\n",
            "üìù Prediction: ACD\n",
            "‚úÖ Actual Answer: AB\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.37 s\n",
            "\n",
            "üîÑ Question 25/30\n",
            "üì§ Model's Raw Output: ACD\n",
            "üìù Prediction: ACD\n",
            "‚úÖ Actual Answer: ACD\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.39 s\n",
            "\n",
            "üîÑ Question 26/30\n",
            "üì§ Model's Raw Output: A D\n",
            "üìù Prediction: AD\n",
            "‚úÖ Actual Answer: AD\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.35 s\n",
            "\n",
            "üîÑ Question 27/30\n",
            "üì§ Model's Raw Output: B C D\n",
            "üìù Prediction: BCD\n",
            "‚úÖ Actual Answer: BCD\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.42 s\n",
            "\n",
            "üîÑ Question 28/30\n",
            "üì§ Model's Raw Output: B\n",
            "üìù Prediction: B\n",
            "‚úÖ Actual Answer: B\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.31 s\n",
            "\n",
            "üîÑ Question 29/30\n",
            "üì§ Model's Raw Output: B\n",
            "üìù Prediction: B\n",
            "‚úÖ Actual Answer: A\n",
            "üéØ Correct? ‚ùå No\n",
            "‚è±Ô∏è Latency: 0.37 s\n",
            "\n",
            "üîÑ Question 30/30\n",
            "üì§ Model's Raw Output: AB\n",
            "üìù Prediction: AB\n",
            "‚úÖ Actual Answer: AB\n",
            "üéØ Correct? ‚úÖ Yes\n",
            "‚è±Ô∏è Latency: 0.32 s\n",
            "\n",
            "üéØ Results\n",
            "‚úÖ Accuracy: 63.33%\n",
            "‚è±Ô∏è Avg Latency: 0.41s\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# üöÄ Benchmark\n",
        "correct = 0\n",
        "latencies = []\n",
        "\n",
        "for i, sample in enumerate(dataset):\n",
        "    print(f\"\\nüîÑ Question {i+1}/{NUM_QUESTIONS}\")\n",
        "\n",
        "    # Use sample directly (no json.loads needed)\n",
        "    prompt = format_prompt(sample[\"question\"], sample[\"choices\"])\n",
        "\n",
        "    # Send prompt to Ollama API\n",
        "    start = time.time()\n",
        "    response = requests.post(\n",
        "        f\"{OLLAMA_API}/api/generate\",\n",
        "        json={\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False\n",
        "        }\n",
        "    )\n",
        "    latency = time.time() - start\n",
        "\n",
        "    output_text = response.json().get(\"response\", \"\")\n",
        "    prediction = extract_answer(output_text)\n",
        "    actual = sample[\"answer\"].strip().upper()\n",
        "    is_correct = (prediction == actual)\n",
        "\n",
        "    correct += int(is_correct)\n",
        "    latencies.append(latency)\n",
        "\n",
        "    # üîç Show model prediction and correct answer\n",
        "    print(\"üì§ Model's Raw Output:\", output_text.strip())\n",
        "    print(\"üìù Prediction:\", prediction)\n",
        "    print(\"‚úÖ Actual Answer:\", actual)\n",
        "    print(\"üéØ Correct?\" , \"‚úÖ Yes\" if is_correct else \"‚ùå No\")\n",
        "    print(\"‚è±Ô∏è Latency:\", round(latency, 2), \"s\")\n",
        "\n",
        "accuracy = correct / NUM_QUESTIONS * 100\n",
        "avg_latency = sum(latencies) / NUM_QUESTIONS\n",
        "\n",
        "print(\"\\nüéØ Results\")\n",
        "print(f\"‚úÖ Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"‚è±Ô∏è Avg Latency: {avg_latency:.2f}s\")\n"
      ],
      "id": "5kJ8EHM2hUNd"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3mryYoMlMyj"
      },
      "id": "F3mryYoMlMyj",
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}